---
---

@string{aps = {American Physical Society,}}

@book{einstein1956investigations,
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation,}
}

@article{einstein1950meaning,
  abbr={AJP},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics,},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers,}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein, A. and Podolsky, B. and Rosen, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.,},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  selected={false}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik,},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{sapkota2021ubiquitous,
  abbr={MobileHCI},
  img={ubiquitous},
  title={Ubiquitous Interactions for Heads-Up Computing: Understanding Users’ Preferences for Subtle Interaction Techniques in Everyday Settings},
  author={Sapkota*, Shardul and Ram*, Ashwin and Zhao, Shengdong},
  journal={23rd International Conference on Mobile Human-Computer Interaction (MobileHCI'21)},
  abstract={In order to satisfy users’ information needs while incurring minimum interference to their ongoing activities, previous studies have proposed using Optical Head-mounted Displays (OHMDs) with different input techniques. However, it is unclear how these techniques compare against one another in terms of being comfortable and non-intrusive to a user’s everyday tasks. Through a wizard-of-oz study, we thus compared four subtle interaction techniques (feet, arms, thumb-index-fingers, and teeth) in three daily hands-busy tasks under different settings (giving a presentation–sitting, carrying bags–walking, and folding clothes–standing). We found that while each interaction technique has its niche, thumb-index-finger interaction has the best overall balance and is most preferred as a cross-scenario subtle interaction technique for smart glasses. We provide further evaluation of thumb-index-finger interaction with an in-the-wild study with 8 users. Our results contribute to an enhanced understanding of user preferences for subtle interaction techniques with smart glasses for everyday use.},
  year={2021},
  publisher={ACM New York, NY, USA},  
  equal={*Denotes equal contribution},
  pdf={ubiquitous.pdf},
  selected={true}
}

@article{kaluarachchi2021eyeknowyou,
  abbr={MobileHCI},
  img={eyeknowyou},
  title={EyeKnowYou: A DIY Toolkit to Support Monitoring Cognitive Load and Actual Screen Time using a Head-Mounted Webcam},
  author={Kaluarachchi, Tharindu and Sapkota, Shardul and Taradel, Jules and Thevenon, Aristée and Matthies, Denys J.C. and Nanayakkara, Suranga},
  journal={Extended Abstracts of the 23rd International Conference on Mobile Human-Computer Interaction (MobileHCI'21)},
  abstract={Studies show that frequent screen exposure and increased cognitive load can cause mental-health issues. Although expensive systems capable of detecting cognitive load and timers counting on-screen time exist, literature has yet to demonstrate measuring both fac- tors across devices. To address this, we propose an inexpensive DIY-approach using a single head-mounted webcam capturing the user’s eye. By classifying camera feed using a 3D Convolutional Neural Network, we can determine increased cognitive load and actual screen time. This works because the camera feed contains corneal surface reflection, as well as physiological parameters that contain information on cognitive load. Even with a small data set, we were able to develop generalised models showing 70% accuracy. To increase the models’ accuracy, we seek the community’s help by contributing more raw data. Therefore, we provide an opensource software and a DIY-guide to make our toolkit accessible to human factors researchers without an engineering background.},
  year={2021},
  publisher={ACM New York, NY, USA},  
  pdf={eyeknowyou.pdf},
  selected={true}
}

@article{zhang2021moment,
  abbr={Sensors},
  img={gradCPT},
  title={Moment-to-Moment Continuous Attention Fluctuation Monitoring through Consumer-Grade EEG Device},
  author={Zhang*, Shan and Yan*, Zihan and Sapkota, Shardul and Zhao, Shengdong and Ooi, Wei Tsang},
  journal={Sensors},
  abstract={While numerous studies have explored using various sensing techniques to measure attention states, moment-to-moment attention fluctuation measurement is unavailable. To bridge this gap, we applied a novel paradigm in psychology, the gradual-onset continuous performance task (gradCPT), to collect the ground truth of attention states. GradCPT allows for the precise labeling of attention fluctuation on an 800 ms time scale. We then developed a new technique for measuring continuous attention fluctuation, based on a machine learning approach that uses the spectral properties of EEG signals as the main features. We demonstrated that, even using a consumer grade EEG device, the detection accuracy of moment-to-moment attention fluctuations was 73.49%. Next, we empirically validated our technique in a video learning scenario and found that our technique match with the classification obtained through thought probes, with an average F1 score of 0.77. Our results suggest the effectiveness of using gradCPT as a ground truth labeling method and the feasibility of using consumer-grade EEG devices for continuous attention fluctuation detection.},
  equal={*Denotes equal contribution},
  volume={21},
  number={10},
  pages={3419},
  year={2021},
  publisher={Multidisciplinary Digital Publishing Institute},
  url={https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8156270/},
  doi={10.3390/s21103419},
  html={https://www.mdpi.com/1424-8220/21/10/3419},
  pdf={gradCPT.pdf},
  selected={true}
}

@article{chan2020prompto,
  abbr={IMWUT},
  img={prompto},
  title={Prompto: Investigating Receptivity to Prompts Based on Cognitive Load from Memory Training Conversational Agent},
  author={Chan, Samantha WT and Sapkota, Shardul and Mathews, Rebecca and Zhang, Haimo and Nanayakkara, Suranga},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  abstract={Prospective memory lapses, which involve forgetting to perform intended actions, affect independent living in older adults. Although memory training using smartphone applications could address them, users are sometimes unaware of available times for training or forget about it, presenting a need for proactive prompts. Existing applications mostly provide time-based prompts and prompts based on users' cognitive contexts remain an under-explored area. We developed Prompto, a conversational memory coach that detects physiological signals to suggest training sessions when users are relaxed and potentially more receptive. Our study with 21 older adults showed that users were more receptive to prompts and memory training under low cognitive load than under high cognitive load. Interviews and an in-the-wild deployment of Prompto indicated that majority of users appreciated the concept, found it helpful and were likely to respond to its prompts. We contribute towards developing technologies with cognitive context-aware prompting based on users' physiological readings.},
  volume={4},
  number={4},
  pages={1--23},
  year={2020},
  publisher={ACM New York, NY, USA},
  url={https://dl.acm.org/doi/10.1145/3432190},
  doi={https://dl.acm.org/doi/10.1145/3432190},
  html={https://dl.acm.org/doi/10.1145/3432190},
  pdf={prompto.pdf},
  selected={true}
}

@article{vega2019byte,
  abbr={CHI EA},
  img={byteit},
  author          = {Vega G{\'a}lvez, Tom{\'a}s and Sapkota, Shardul and Dancu, Alexandru and Maes, Pattie},
  title           = {Byte. it: discreet teeth gestures for mobile device interaction},
  journal         = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems},
  abstract={Byte.it is an exploration of the feasibility of using miniaturized, discreet hardware for teeth-clicking as hands-free input for wearable computing. Prior work has been able to identify teeth-clicking of different teeth groups. Byte.it expands on this work by exploring the use of a smaller and more discreetly positioned sensor suite (accelerometer and gyroscope) for detecting four different teeth-clicks for everyday human-computer interaction. Initial results show that an unobtrusive position on the lower mastoid and mandibular condyle can be used to classify teeth-clicking of four different teeth groups with an accuracy of 89%.},
  pages           = {1--6},
  pdf             = {},
  year            = {2019},
  url={https://dl.acm.org/doi/10.1145/3290607.3312925},
  doi={https://dl.acm.org/doi/10.1145/3290607.3312925},
  html={https://dl.acm.org/doi/10.1145/3290607.3312925},
  pdf={byteit.pdf},
  selected={true}
}

@article{janaka2023can,
  abbr={CHI},
  img={nuwan_icon},
  title={Can icons outperform text? understanding the role of pictograms in ohmd notifications},
  author={Janaka, Nuwan Nanayakkarawasam Peru Kandage and Zhao, Shengdong and Sapkota, Shardul},
  journal={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  abstract={Optical see-through head-mounted displays (OHMDs) can provide just-in-time digital assistance to users while they are engaged in ongoing tasks. However, given users’ limited attentional resources when multitasking, there is a need to concisely and accurately present information in OHMDs. Existing approaches for digital information presentation involve using either text or pictograms. While pictograms have enabled rapid recognition and easier use in warning messages and trafc signs, most studies using pictograms for digital notifcations have exhibited unfavorable results. We thus conducted a series of four iterative studies to understand how we can support efective notifcation presentation on OHMDs during multitasking scenarios. We fnd that while icon-augmented notifcations can outperform text-only notifcations, their efectiveness depends on icon familiarity, encoding density, and environmental brightness. We reveal design implications when using iconaugmented notifcations in OHMDs and present plausible reasons for the observed disparity in literature},
  volume={4},
  number={4},
  pages={1--23},
  year={2023},
  publisher={ACM New York, NY, USA},
  url={https://dl.acm.org/doi/pdf/10.1145/3544548.3580891},
  doi={https://dl.acm.org/doi/pdf/10.1145/3544548.3580891},
  html={https://dl.acm.org/doi/pdf/10.1145/3544548.3580891},
  pdf={nuwan_icon.pdf},
  selected={true}
}